---
created: 2024-10-05 07:45:11
updated: 2024-10-05 07:46:07
tags:
  - RAG
  - 논문
dg-publish: true
---

# Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection

> 논문: https://arxiv.org/abs/2310.11511

## 초록

뛰어난 기능에도 불구하고 대규모 언어 모델(LLM)은 캡슐화된 매개변수 지식에만 의존하기 때문에 사실과 다른 부정확한 응답을 생성하는 경우가 많습니다. 관련 지식 검색을 통해 LM을 보강하는 임시 접근 방식인 검색 증강 생성(RAG)은 이러한 문제를 줄여줍니다. 그러나 검색의 필요성이나 구절의 관련성 여부에 관계없이 무차별적으로 검색된 구절을 고정된 수만큼 검색하여 통합하면 LM의 활용성이 떨어지거나 도움이 되지 않는 응답을 생성할 수 있습니다. 저희는 검색과 자기 반성을 통해 LM의 품질과 사실성을 향상시키는 자기 반성적 검색 증강 생성(Self-RAG)이라는 새로운 프레임워크를 도입했습니다. 저희 프레임워크는 필요에 따라 구절을 적응적으로 검색하는 단일 임의의 LM을 학습시키고, 반사 토큰이라는 특수 토큰을 사용하여 검색된 구절과 자체 세대를 생성 및 반영합니다. 리플렉션 토큰을 생성하면 추론 단계에서 LM을 제어할 수 있으므로 다양한 작업 요구 사항에 맞게 동작을 조정할 수 있습니다. 실험에 따르면 Self-RAG(7B 및 13B 파라미터)는 다양한 작업 세트에서 최첨단 LLM 및 검색 증강 모델보다 훨씬 뛰어난 성능을 발휘합니다. 특히, Self-RAG는 오픈 도메인 QA, 추론 및 사실 확인 작업에서 ChatGPT 및 검색 증강 Llama2-chat보다 성능이 뛰어나며, 이러한 모델에 비해 긴 형식의 생성에 대한 사실성 및 인용 정확도 개선에 있어 상당한 이점을 보여줍니다.