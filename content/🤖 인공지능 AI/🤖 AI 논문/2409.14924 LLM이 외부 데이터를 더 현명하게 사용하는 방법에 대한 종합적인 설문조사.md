---
created: 2024-10-06 09:15:38
updated: 2024-10-06 09:19:39
tags:
  - 논문
  - RAG
  - LLM
dg-publish: true
---

# Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely

> 논문: https://arxiv.org/abs/2409.14924

## 초록

외부 데이터로 증강된 대규모 언어 모델(LLM)은 실제 작업을 완료하는 데 있어 놀라운 능력을 보여 왔습니다. 검색 증강 생성(RAG) 및 파인튜닝과 같이 외부 데이터를 LLM에 통합하는 기술은 점점 더 많은 관심을 받으며 광범위하게 적용되고 있습니다. 그럼에도 불구하고 다양한 전문 분야에 걸쳐 데이터 증강 LLM을 효과적으로 배포하는 데는 상당한 어려움이 있습니다. 이러한 과제에는 관련 데이터를 검색하고 사용자의 의도를 정확하게 해석하는 것부터 복잡한 작업을 위해 LLM의 추론 기능을 완전히 활용하는 것까지 다양한 문제가 포함됩니다. 데이터 증강 LLM 애플리케이션을 위한 만능 솔루션은 없다고 생각합니다. 실제로 성과 저하는 종종 작업의 핵심 초점을 정확하게 파악하지 못하거나 작업의 본질적으로 더 나은 해결을 위해 여러 기능을 혼합해야 하기 때문에 발생합니다. 이 설문조사에서는 필요한 외부 데이터의 유형과 업무의 주요 초점에 따라 ==사용자 쿼리를 명시적 사실 쿼리(explicit fact queries), 암묵적 사실 쿼리(implicit fact queries), 해석 가능한 근거 쿼리(interpretable rationale queries), 숨겨진 근거 쿼리(hidden rationale queries)의 네 가지 수준으로 분류하는 RAG 업무 분류 방법==을 제안합니다. 이러한 수준의 쿼리를 정의하고, 관련 데이터셋을 제공하며, 이러한 문제를 해결하기 위한 주요 과제와 가장 효과적인 기술을 요약합니다. 마지막으로 외부 데이터를 LLM에 통합하는 세 가지 주요 형태인 컨텍스트, 소규모 모델, 파인튜닝에 대해 논의하며 각각의 강점과 한계, 해결하기에 적합한 문제 유형을 강조합니다. 이 작업은 독자들이 LLM 애플리케이션 구축 시 데이터 요구 사항과 주요 병목 현상을 철저히 이해하고 분석하여 다양한 문제에 대한 해결책을 제시하고 이러한 애플리케이션을 체계적으로 개발하는 데 도움이 되는 가이드 역할을 하는 것을 목표로 합니다.

